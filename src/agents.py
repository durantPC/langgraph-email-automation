from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from .structure_outputs import *
from .prompts import (
    CATEGORIZE_EMAIL_PROMPT,
    GENERATE_RAG_QUERIES_PROMPT,
    EMAIL_WRITER_PROMPT,
    EMAIL_PROOFREADER_PROMPT,
    GENERATE_RAG_ANSWER_PROMPT,
    GENERATE_RAG_ANSWER_PRODUCT_ENQUIRY,
    GENERATE_RAG_ANSWER_CUSTOMER_COMPLAINT,
    GENERATE_RAG_ANSWER_CUSTOMER_FEEDBACK
)
import os

class Agents():
    def __init__(self, api_key=None, reply_model=None, embedding_model=None, signature=None, greeting=None, closing=None, reply_api_base=None, embedding_api_base=None):
        # ä½¿ç”¨APIè°ƒç”¨æ¨¡å‹
        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„api_keyï¼Œå¦åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        if api_key is None:
            api_key = os.getenv("SILICONFLOW_API_KEY")
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ° API å¯†é’¥ï¼Œè¯·åœ¨ç³»ç»Ÿè®¾ç½®ä¸­é…ç½®æˆ–è®¾ç½® SILICONFLOW_API_KEY ç¯å¢ƒå˜é‡")
        
        # ä½¿ç”¨ä¼ å…¥çš„å›å¤æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
        if reply_model is None:
            reply_model = os.getenv("REPLY_MODEL", "moonshotai/Kimi-K2-Thinking")
        
        # ä½¿ç”¨ä¼ å…¥çš„API base URLï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼ˆç¡…åŸºæµåŠ¨ï¼‰
        if reply_api_base is None:
            reply_api_base = "https://api.siliconflow.cn/v1"
        if embedding_api_base is None:
            embedding_api_base = "https://api.siliconflow.cn/v1"
        
        self.qwen_llm = ChatOpenAI(
            model=reply_model,  # ä½¿ç”¨ä¼ å…¥çš„æ¨¡å‹
            temperature=0.1,
            openai_api_key=api_key,
            openai_api_base=reply_api_base
        )
        qwen_llm = self.qwen_llm  # ä¿æŒå‘åå…¼å®¹
        
        # QA assistant chat - å°è¯•ä½¿ç”¨åµŒå…¥æ¨¡å‹ï¼Œå¤±è´¥åˆ™ç”¨æœ¬åœ°æ¨¡å‹
        if embedding_model is None:
            embedding_model = os.getenv("EMBEDDING_MODEL", "Qwen/Qwen3-Embedding-4B")
        
        try:
            from langchain_openai import OpenAIEmbeddings
            embeddings = OpenAIEmbeddings(
                model=embedding_model,  # ä½¿ç”¨ä¼ å…¥çš„åµŒå…¥æ¨¡å‹
                openai_api_key=api_key,
                openai_api_base=embedding_api_base,
                request_timeout=60  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°60ç§’ï¼Œå› ä¸ºåµŒå…¥æ¨¡å‹å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
            )
        except:
            # ä½¿ç”¨æœ¬åœ°åµŒå…¥æ¨¡å‹ä½œä¸ºå¤‡ç”¨
            from langchain_community.embeddings import HuggingFaceEmbeddings
            embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
            )
        
        # æ ¹æ®æ¨¡å‹ç»´åº¦è‡ªåŠ¨é€‰æ‹©å¯¹åº”çš„æ•°æ®åº“ç›®å½•
        # é¦–å…ˆå°è¯•æ ¹æ®æ¨¡å‹åç§°æ¨æ–­ç»´åº¦ï¼ˆæ›´å¯é ï¼‰
        current_dim = None
        embedding_model_lower = embedding_model.lower() if embedding_model else ""
        
        # æ ¹æ®æ¨¡å‹åç§°æ¨æ–­ç»´åº¦
        if "qwen3-embedding-8b" in embedding_model_lower or "embedding-8b" in embedding_model_lower:
            current_dim = 4096
            print(f"ğŸ“ [ç»´åº¦æ£€æµ‹] æ ¹æ®æ¨¡å‹åç§°æ¨æ–­: {embedding_model} -> 4096ç»´")
        elif "qwen3-embedding-4b" in embedding_model_lower or "embedding-4b" in embedding_model_lower:
            current_dim = 2560
            print(f"ğŸ“ [ç»´åº¦æ£€æµ‹] æ ¹æ®æ¨¡å‹åç§°æ¨æ–­: {embedding_model} -> 2560ç»´")
        elif "embedding-2b" in embedding_model_lower or "embedding-1.5b" in embedding_model_lower:
            current_dim = 1024
            print(f"ğŸ“ [ç»´åº¦æ£€æµ‹] æ ¹æ®æ¨¡å‹åç§°æ¨æ–­: {embedding_model} -> 1024ç»´")
        else:
            # å¦‚æœæ— æ³•ä»åç§°æ¨æ–­ï¼Œå°è¯•é€šè¿‡APIè°ƒç”¨æ£€æµ‹
            try:
                print(f"ğŸ“ [ç»´åº¦æ£€æµ‹] å°è¯•é€šè¿‡APIè°ƒç”¨æ£€æµ‹ç»´åº¦...")
                test_embedding = embeddings.embed_query("test")
                current_dim = len(test_embedding)
                print(f"ğŸ“ [ç»´åº¦æ£€æµ‹] APIè°ƒç”¨æˆåŠŸ: {embedding_model} -> {current_dim}ç»´")
            except Exception as e:
                print(f"âš ï¸  [ç»´åº¦æ£€æµ‹] APIè°ƒç”¨å¤±è´¥: {e}")
                current_dim = None
        
        # æ ¹æ®ç»´åº¦é€‰æ‹©æ•°æ®åº“ç›®å½•
        if current_dim == 1024:
            db_path = "db_1024"
        elif current_dim == 2560:
            db_path = "db_2560"
        elif current_dim == 4096:
            db_path = "db_4096"
        else:
            # æœªçŸ¥ç»´åº¦ï¼Œä½¿ç”¨ç»´åº¦ä½œä¸ºç›®å½•å
            db_path = f"db_{current_dim}" if current_dim else "db"
            if current_dim:
                print(f"â„¹ï¸  ä½¿ç”¨è‡ªå®šä¹‰ç»´åº¦æ•°æ®åº“: {db_path}")
            else:
                print(f"âš ï¸  è­¦å‘Š: æ— æ³•ç¡®å®šç»´åº¦ï¼Œä½¿ç”¨é»˜è®¤ç›®å½•: {db_path}")
                print(f"   åµŒå…¥æ¨¡å‹: {embedding_model}")
                print(f"   å»ºè®®: æ£€æŸ¥æ¨¡å‹åç§°æˆ–ç¡®ä¿APIè°ƒç”¨æˆåŠŸ")
        
        # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
        if not os.path.exists(db_path):
            print(f"âš ï¸  è­¦å‘Š: æ•°æ®åº“ç›®å½• {db_path} ä¸å­˜åœ¨ï¼")
            print(f"   å½“å‰åµŒå…¥æ¨¡å‹: {embedding_model}")
            print(f"   å½“å‰æ¨¡å‹ç»´åº¦: {current_dim}")
            print(f"   è¯·è¿è¡Œå¯¹åº”çš„åˆ›å»ºè„šæœ¬ï¼š")
            if current_dim == 1024:
                print(f"   python create_index_1024.py")
            elif current_dim == 2560:
                print(f"   python create_index_2560.py")
            elif current_dim == 4096:
                print(f"   python create_index_4096.py")
            else:
                print(f"   è¯·åˆ›å»º {db_path} ç›®å½•çš„æ•°æ®åº“")
            print(f"   æˆ–è€…ä½¿ç”¨å…¶ä»–å·²å­˜åœ¨çš„æ•°æ®åº“ç›®å½•")
            # åˆ›å»ºç©ºæ•°æ®åº“ï¼ˆä½†ä¼šæç¤ºç”¨æˆ·éœ€è¦è¿è¡Œåˆ›å»ºè„šæœ¬ï¼‰
            # ä¼˜å…ˆä½¿ç”¨ä¸æŒ‡å®š tenant/database çš„æ–¹å¼ï¼ˆå…¼å®¹æ—§æ•°æ®åº“ï¼‰
            try:
                # æ–¹å¼1ï¼šç›´æ¥ä½¿ç”¨ persist_directoryï¼Œä¸æŒ‡å®š tenant/databaseï¼ˆå…¼å®¹æ—§æ•°æ®åº“ï¼‰
                vectorstore = Chroma(
                    persist_directory=db_path, 
                    embedding_function=embeddings,
                    collection_name="langchain"
                )
            except Exception as e1:
                # æ–¹å¼2ï¼šå¦‚æœæ–¹å¼1å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬çš„ tenant/database
                try:
                    import chromadb
                    client = chromadb.PersistentClient(
                        path=db_path,
                        tenant="default_tenant",
                        database="default_database"
                    )
                    vectorstore = Chroma(
                        client=client,
                        embedding_function=embeddings,
                        collection_name="langchain"
                    )
                except Exception as e2:
                    # æ–¹å¼3ï¼šå¦‚æœéƒ½å¤±è´¥ï¼Œå°è¯•ä¸æŒ‡å®š tenant å’Œ database
                    print(f"âš ï¸  ä½¿ç”¨å…¼å®¹æ¨¡å¼åˆ›å»ºæ•°æ®åº“: {type(e1).__name__}: {str(e1)[:100]}")
                    try:
                        import chromadb
                        client = chromadb.PersistentClient(path=db_path)
                        vectorstore = Chroma(
                            client=client,
                            embedding_function=embeddings,
                            collection_name="langchain"
                        )
                    except Exception as e3:
                        # æœ€åå›é€€ï¼šå®Œå…¨ä¸ä½¿ç”¨ clientï¼Œè®© langchain_chroma è‡ªå·±å¤„ç†
                        print(f"âš ï¸  å°è¯•æœ€åå…¼å®¹æ¨¡å¼: {type(e3).__name__}: {str(e3)[:100]}")
                        vectorstore = Chroma(
                            persist_directory=db_path, 
                            embedding_function=embeddings
                        )
            print(f"   âš ï¸  å·²åˆ›å»ºç©ºæ•°æ®åº“ï¼Œè¯·è¿è¡Œåˆ›å»ºè„šæœ¬å¡«å……æ•°æ®")
        else:
            # æ•°æ®åº“å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨
            # ä¼˜å…ˆä½¿ç”¨ä¸æŒ‡å®š tenant/database çš„æ–¹å¼ï¼ˆå…¼å®¹æ—§æ•°æ®åº“ï¼‰
            try:
                # æ–¹å¼1ï¼šç›´æ¥ä½¿ç”¨ persist_directoryï¼Œä¸æŒ‡å®š tenant/databaseï¼ˆå…¼å®¹æ—§æ•°æ®åº“ï¼‰
                vectorstore = Chroma(
                    persist_directory=db_path, 
                    embedding_function=embeddings,
                    collection_name="langchain"
                )
            except Exception as e1:
                # æ–¹å¼2ï¼šå¦‚æœæ–¹å¼1å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬çš„ tenant/database
                try:
                    import chromadb
                    client = chromadb.PersistentClient(
                        path=db_path,
                        tenant="default_tenant",
                        database="default_database"
                    )
                    vectorstore = Chroma(
                        client=client,
                        embedding_function=embeddings,
                        collection_name="langchain"
                    )
                except Exception as e2:
                    # æ–¹å¼3ï¼šå¦‚æœéƒ½å¤±è´¥ï¼Œå°è¯•ä¸æŒ‡å®š tenant å’Œ database
                    print(f"âš ï¸  ä½¿ç”¨å…¼å®¹æ¨¡å¼åŠ è½½æ•°æ®åº“: {type(e1).__name__}: {str(e1)[:100]}")
                    try:
                        import chromadb
                        client = chromadb.PersistentClient(path=db_path)
                        vectorstore = Chroma(
                            client=client,
                            embedding_function=embeddings,
                            collection_name="langchain"
                        )
                    except Exception as e3:
                        # æœ€åå›é€€ï¼šå®Œå…¨ä¸ä½¿ç”¨ clientï¼Œè®© langchain_chroma è‡ªå·±å¤„ç†
                        print(f"âš ï¸  å°è¯•æœ€åå…¼å®¹æ¨¡å¼: {type(e3).__name__}: {str(e3)[:100]}")
                        vectorstore = Chroma(
                            persist_directory=db_path, 
                            embedding_function=embeddings
                        )
            print(f"âœ… ä½¿ç”¨ {current_dim} ç»´æ•°æ®åº“: {db_path}")
            # æ£€æŸ¥æ•°æ®åº“ä¸­çš„æ–‡æ¡£æ•°é‡
            try:
                collection = vectorstore._collection
                count = collection.count()
                print(f"ğŸ“Š [æ•°æ®åº“ä¿¡æ¯] æ•°æ®åº“ä¸­å…±æœ‰ {count} ä¸ªæ–‡æ¡£å—")
            except Exception as e:
                print(f"âš ï¸ [æ•°æ®åº“ä¿¡æ¯] æ— æ³•è·å–æ–‡æ¡£æ•°é‡: {e}")
        
        # åˆ›å»ºåŸºç¡€æ£€ç´¢å™¨ï¼ˆç”¨äºå¿«é€Ÿæ£€ç´¢ï¼‰
        # ä½¿ç”¨ç›¸ä¼¼åº¦æ£€ç´¢ï¼ˆsimilarityï¼‰è€Œä¸æ˜¯MMRï¼Œå› ä¸ºMMRéœ€è¦æ›´å¤šè®¡ç®—æ—¶é—´
        # å¢åŠ æ£€ç´¢æ•°é‡ï¼Œç¡®ä¿å°æ–‡æ¡£ä¹Ÿèƒ½è¢«æ£€ç´¢åˆ°
        base_retriever = vectorstore.as_retriever(
            search_type="similarity",  # ä½¿ç”¨ç›¸ä¼¼åº¦æ£€ç´¢ï¼Œé€Ÿåº¦æ›´å¿«
            search_kwargs={"k": 20}  # ä»15å¢åŠ åˆ°20ï¼Œæé«˜è¦†ç›–ç‡
        )
        
        # ä¸ºä¸åŒé‚®ä»¶ç±»å‹åˆ›å»ºä¸“é—¨çš„æ£€ç´¢å™¨
        # äº§å“å’¨è¯¢ï¼šä½¿ç”¨similarityæ£€ç´¢ä»¥æé«˜é€Ÿåº¦ï¼ˆMMRè™½ç„¶å¤šæ ·æ€§æ›´å¥½ï¼Œä½†é€Ÿåº¦æ…¢2-3å€ï¼‰
        # æ³¨æ„ï¼šsimilarityæ£€ç´¢å·²ç»è¶³å¤Ÿå‡†ç¡®ï¼ŒLLMä¼šå¤„ç†é‡å¤å†…å®¹
        product_retriever = vectorstore.as_retriever(
            search_type="similarity",  # æ”¹ä¸ºsimilarityï¼Œé€Ÿåº¦æå‡2-3å€
            search_kwargs={
                "k": 12  # ä»15å‡å°‘åˆ°12ï¼Œå¹³è¡¡é€Ÿåº¦å’Œè¦†ç›–ç‡
            }
        )
        
        # å®¢æˆ·æŠ•è¯‰ï¼šéœ€è¦å¿«é€Ÿæ‰¾åˆ°å¤„ç†æµç¨‹å’Œè§£å†³æ–¹æ¡ˆ
        complaint_retriever = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 10}  # ä»6å¢åŠ åˆ°10ï¼Œæé«˜è¦†ç›–ç‡
        )
        
        # å®¢æˆ·åé¦ˆï¼šéœ€è¦æ‰¾åˆ°ç›¸å…³åŠŸèƒ½å’Œæ”¹è¿›å»ºè®®
        feedback_retriever = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 8}  # ä»5å¢åŠ åˆ°8ï¼Œæé«˜è¦†ç›–ç‡
        )
        
        # ä¿å­˜retrieverå’Œvectorstoreä¾›è°ƒè¯•ä½¿ç”¨
        self.retriever = base_retriever  # é»˜è®¤ä½¿ç”¨åŸºç¡€æ£€ç´¢å™¨
        self.product_retriever = product_retriever
        self.complaint_retriever = complaint_retriever
        self.feedback_retriever = feedback_retriever
        self.vectorstore = vectorstore

        # ä¿å­˜æ¨¡æ¿è®¾ç½®
        self.signature = signature or "Agentia å›¢é˜Ÿ"
        self.greeting = greeting or "å°Šæ•¬çš„å®¢æˆ·ï¼Œæ‚¨å¥½ï¼"
        self.closing = closing or "ç¥å¥½ï¼"

        # Categorize email chain
        email_category_prompt = PromptTemplate(
            template=CATEGORIZE_EMAIL_PROMPT, 
            input_variables=["email"]
        )
        self.categorize_email = (
            email_category_prompt | 
            qwen_llm.with_structured_output(CategorizeEmailOutput)
        )

        # Used to design queries for RAG retrieval
        generate_query_prompt = PromptTemplate(
            template=GENERATE_RAG_QUERIES_PROMPT, 
            input_variables=["email"]
        )
        self.design_rag_queries = (
            generate_query_prompt | 
            qwen_llm.with_structured_output(RAGQueriesOutput)
        )
        
        # Generate answer to queries using RAG (é€šç”¨ç‰ˆæœ¬)
        qa_prompt = ChatPromptTemplate.from_template(GENERATE_RAG_ANSWER_PROMPT)
        self.generate_rag_answer = (
            {"context": base_retriever, "question": RunnablePassthrough()}
            | qa_prompt
            | qwen_llm
            | StrOutputParser()
        )
        
        # ä¸ºä¸åŒé‚®ä»¶ç±»å‹åˆ›å»ºä¸“é—¨çš„RAGç­”æ¡ˆç”Ÿæˆå™¨
        # äº§å“å’¨è¯¢
        product_qa_prompt = ChatPromptTemplate.from_template(GENERATE_RAG_ANSWER_PRODUCT_ENQUIRY)
        self.generate_rag_answer_product = (
            {"context": product_retriever, "question": RunnablePassthrough()}
            | product_qa_prompt
            | qwen_llm
            | StrOutputParser()
        )
        
        # å®¢æˆ·æŠ•è¯‰
        complaint_qa_prompt = ChatPromptTemplate.from_template(GENERATE_RAG_ANSWER_CUSTOMER_COMPLAINT)
        self.generate_rag_answer_complaint = (
            {"context": complaint_retriever, "question": RunnablePassthrough()}
            | complaint_qa_prompt
            | qwen_llm
            | StrOutputParser()
        )
        
        # å®¢æˆ·åé¦ˆ
        feedback_qa_prompt = ChatPromptTemplate.from_template(GENERATE_RAG_ANSWER_CUSTOMER_FEEDBACK)
        self.generate_rag_answer_feedback = (
            {"context": feedback_retriever, "question": RunnablePassthrough()}
            | feedback_qa_prompt
            | qwen_llm
            | StrOutputParser()
        )

        # Used to write a draft email based on category and related informations
        # æ„å»ºåŠ¨æ€çš„é‚®ä»¶å†™ä½œæç¤ºè¯ï¼ˆä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„æ¨¡æ¿ï¼‰
        # ä½¿ç”¨ replace è€Œä¸æ˜¯ formatï¼Œé¿å…ä¸ prompt ä¸­çš„ JSON æ ¼å¼å†²çª
        email_writer_prompt_template = EMAIL_WRITER_PROMPT.replace('{greeting}', self.greeting).replace('{closing}', self.closing).replace('{signature}', self.signature)
        
        writer_prompt = ChatPromptTemplate.from_messages(
            [
                ("system", email_writer_prompt_template),
                MessagesPlaceholder("history"),
                ("human", "{email_information}")
            ]
        )
        self.email_writer = (
            writer_prompt | 
            qwen_llm.with_structured_output(WriterOutput)
        )

        # Verify the generated email
        proofreader_prompt = PromptTemplate(
            template=EMAIL_PROOFREADER_PROMPT, 
            input_variables=["initial_email", "generated_email"]
        )
        self.email_proofreader = (
            proofreader_prompt | 
            qwen_llm.with_structured_output(ProofReaderOutput) 
        )